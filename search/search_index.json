{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"SLOTH","text":"The multiphase-field multicomponent framework of the PLEIADES platform     based on MFEM  <ul> <li> <p>Features</p> <ul> <li>Phase-field modelling</li> <li>Finite Element, AMR</li> <li>Unsteady, nonlinear, coupled problems</li> <li>Massively parallel MPI implementation </li> <li>Calphad-informed phase-field</li> </ul> </li> <li> <p>News</p> <ul> <li>SLOTH at NuMat Conference [10/24]</li> </ul> </li> <li> <p>Latest Release</p> <p>(Coming  soon)</p> </li> <li> <p>Contact</p> <p>Use the Github issue tracker to report bugs or comments. </p> <p>See the About page for contact and license information.</p> </li> </ul>"},{"location":"physical_description.html","title":"Physical description","text":""},{"location":"physical_description.html#welcome-to-the-documentation-of-the-phase-field-solver-based-on-mfem","title":"Welcome to the documentation of the Phase-Field Solver based on MFEM","text":""},{"location":"About/index.html","title":"About the SLOTH project","text":""},{"location":"About/index.html#project-summary","title":"Project summary","text":"<p>Phase-field methods represent a versatile and effective approach to modelling the spatiotemporal evolution of complex physical systems that exhibit significant heterogeneities, such as phase transitions, coalescence, and cracking. These methods have found extensive application in the field of materials science, including in the modelling of the behaviour of nuclear fuels. </p> <p>The phase-field approach has also been employed in recent studies conducted with the multiphysics computational tools of the PLEIADES platform<sup>1</sup>. Broadly speaking, the <code>PLEIADES</code>/Fuel Performance Codes<sup>2</sup> aim at providing a state-of-the-art multiphysics multiscale description of the fuel under irradiated conditions. The inclusion of an advanced multiphysics and multiscale modelling such as phase-field, is a logical step forward. Consequently, the CEA is developing SLOTH, a multiphase-field multicomponent framework, dedicated to the study of fuel behaviour at different scales of description, from nominal operating conditions to severe accident conditions. </p> <p><code>PLEIADES/SLOTH</code> is developed at CEA under LPGL license (Version 3). It is based on the the <code>MFEM</code> Finite Element library<sup>3</sup>, which already includes the main features to have a robust, flexible and massively parallel implementation of the solution algorithms.</p> <p>Incipient melting in a pellet fragment under an ad-hoc temperature dependent enthalpy of melting</p> <p>Polycristalline microstructure with 30 grains</p> <p>Spinodal decomposition</p>"},{"location":"About/index.html#contributors","title":"Contributors","text":"<ul> <li> <p>Modelling &amp; Development Team</p> <ul> <li>Cl\u00e9ment Intro\u00efni (Phase-Field, Computer Science, Material Science)</li> <li>Rapha\u00ebl Prat (Computer Science, HPC)</li> </ul> </li> <li> <p>Students Team</p> <ul> <li>Alessandro Scapini (PhD 2024-2027)</li> <li>Cl\u00e9ment Plumecocq (PhD 2023-2026)</li> <li>Mouad Bakhkakh (Master 2024)</li> <li>Etienne Delobre (Master 2023)</li> </ul> </li> </ul> <ol> <li> <p>St\u00e9phane Bernaud, Isabelle Rami\u00e8re, Guillaume Latu, and Bruno Michel. Pleiades: a numerical framework dedicated to the multiphysics and multiscale nuclear fuel behavior simulation. Annals of Nuclear Energy, 205:110577, 2024.\u00a0\u21a9</p> </li> <li> <p>C Intro\u00efni, I Rami\u00e8re, J Sercombe, B Michel, T Helfer, and J Fauque. Alcyone: the fuel performance code of the pleiades platform dedicated to pwr fuel rods behavior. Annals of Nuclear Energy, 207:110711, 2024.\u00a0\u21a9</p> </li> <li> <p>Robert Anderson, Julian Andrej, Andrew Barker, Jamie Bramwell, Jean-Sylvain Camier, Jakub Cerveny, Veselin Dobrev, Yohann Dudouit, Aaron Fisher, Tzanio Kolev, and others. Mfem: a modular finite element methods library. Computers &amp; Mathematics with Applications, 81:42\u201374, 2021.\u00a0\u21a9</p> </li> </ol>"},{"location":"Applications/index.html","title":"Coming soon","text":""},{"location":"Documentation/Code/index.html","title":"Coming soon","text":""},{"location":"Documentation/Physical/index.html","title":"Coming soon","text":""},{"location":"Documentation/Physical/index.html#introduction-to-the-phase-field-modelling","title":"Introduction to the phase-field modelling","text":""},{"location":"Documentation/Physical/index.html#cahn-hilliard-model","title":"Cahn-Hilliard model","text":""},{"location":"Documentation/Physical/index.html#allen-cahn-model","title":"Allen-Cahn model","text":""},{"location":"Documentation/Physical/model1.html","title":"Model1","text":""},{"location":"Documentation/Physical/model1.html#model-1","title":"Model 1","text":"<p>this is the modle 1</p>"},{"location":"Documentation/Physical/model1.html#section-model-1","title":"section model 1","text":""},{"location":"Documentation/Physical/model2.html","title":"Model2","text":""},{"location":"Documentation/Physical/model2.html#model-1","title":"Model 1","text":"<p>this is the modle 1</p>"},{"location":"Documentation/Physical/model2.html#section-model-1","title":"section model 1","text":""},{"location":"Documentation/Physical/model3.html","title":"Model3","text":""},{"location":"Documentation/Physical/model3.html#model-1","title":"Model 1","text":"<p>this is the modle 1</p>"},{"location":"Documentation/Physical/model3.html#section-model-1","title":"section model 1","text":""},{"location":"Documentation/User/index.html","title":"Coming soon","text":""},{"location":"Documentation/User/AnalyticalVariables/index.html","title":"AnalyticalFunctions (Coming soon)","text":"<p>This page provides a comprehensive overview of the analytical functions available in <code>SLOTH</code>, along with detailed instructions on how to define each function.</p>"},{"location":"Documentation/User/BoundaryConditions/index.html","title":"Boundary Conditions (coming soon)","text":"<p>This page describes the use of boundary conditions in <code>SLOTH</code>.</p>"},{"location":"Documentation/User/Convergence/index.html","title":"Physical Convergence (Coming soon)","text":"<p>This page is dedicated to the <code>PhysicalConvergence</code> object. </p> <p>Use of <code>PhysicalConvergence</code></p> <p>It is worth mentioning that this object is disable. It will be enabled when fixed point algorithm and automatic time-step splitting are integrated.</p>"},{"location":"Documentation/User/Integrators/index.html","title":"Integrators","text":"<p>Coming soon</p>"},{"location":"Documentation/User/Meshing/index.html","title":"Meshing (coming soon)","text":"<p>This page describes building a mesh in <code>SLOTH</code> either by considering a <code>GMSH</code> file or by using directly <code>MFEM</code> features.</p>"},{"location":"Documentation/User/Operators/index.html","title":"Operators (Coming soon)","text":"<p>This page introduces the concept of <code>Operator</code> for <code>SLOTH</code> and provides a comprehensive overview of available <code>Operator</code> objects including all information on how to use them.</p>"},{"location":"Documentation/User/Parameters/index.html","title":"Parameters (Coming soon)","text":"<p>This page focuses on the <code>Parameters</code> and <code>Parameter</code> objects specially designed for <code>SLOTH</code>.</p>"},{"location":"Documentation/User/PostProcessing/index.html","title":"Post-Processing (Coming soon)","text":"<p>This page presents all Post-processing features and describes all parameters with default values.</p>"},{"location":"Documentation/User/Problems/index.html","title":"Problems (Coming soon)","text":"<p>This page lists all the <code>SLOTH</code> <code>Problem</code> and explains how to use them. </p>"},{"location":"Documentation/User/Time/index.html","title":"Time discretization (Coming soon)","text":"<p>This page is dedicated to the <code>TimeDiscretization</code> object.</p>"},{"location":"Documentation/User/Variables/index.html","title":"Variables (Coming soon)","text":"<p>This page described how to define and manage variables in <code>SLOTH</code>.</p>"},{"location":"References/index.html","title":"Coming soon","text":""},{"location":"Started/index.html","title":"A Step-By-Step Guide","text":"<p>This page provides users with comprehensive information on installing and using SLOTH, making it easier to develop custom applications. </p> <ul> <li>Installation guide </li> <li>Examples</li> <li>Code quality</li> <li>How to build an application</li> </ul> <p>Before following these instructions, users are required to clone the code of SLOTH, which is available for download from Github. </p> <pre><code>git clone https://github.com/Collab4Sloth/SLOTH.git \n</code></pre> <p>SLOTH project</p> <p>Scanning this QR code will direct users to other associated repositories: </p> DocumentationGalleryStudies <p>This repository is dedicted to the documentation of the project including the user manual and the physical description of models implemented in SLOTH.</p> <pre><code>git clone https://github.com/Collab4Sloth/Documentation.git\n</code></pre> <p>This repository is the Hall of Fame of simulations performed with SLOTH.</p> <pre><code>git clone https://github.com/Collab4Sloth/Gallery.git\n</code></pre> <p>Please note that this repository is still under construction. It will contain all the information from public studies conducted with SLOTH. </p> <pre><code>git clone https://github.com/Collab4Sloth/Studies.git\n</code></pre>"},{"location":"Started/Examples/index.html","title":"Coming soon","text":""},{"location":"Started/HowTo/index.html","title":"Index","text":""},{"location":"Started/HowTo/index.html#howto","title":"HowTo","text":"<p>This page comprises two sections:</p> <ul> <li>The first section provides a description of the basic features of a SLOTH test as implemented in a very simple simulation;</li> <li>The second section offers tutorials that provide comprehensive explanations of the more advanced features and how to use them to run more complex simulations.</li> </ul>"},{"location":"Started/HowTo/Simple/index.html","title":"Basic features","text":"<p>This page provides a description of the basic features of a <code>SLOTH</code> test as implemented in a very simple simulation.  This description is based on a very simple example, but the data structure shown is common to all <code>SLOTH</code> simulations.</p> <p>On this page, the users can find the most important parts of a <code>SLOTH</code> input dataset and go to the pages of the User Manual that give all the options and the instructions for using them.</p> <p>Statement of the problem</p> <p>The current description is based on a simple example code that solves the Allen-Cahn equation in a 1D domain \u03a9=[0,R]\\Omega=[0,R]\u03a9=[0,R] with R=10\u22123R=10^{-3}R=10\u22123. </p> Governing equationBoundary conditionsParametersNumerical scheme <p>Let us consider the following set of governing equations:</p> <p><p>\u2202\u03d5\u2202t=M\u03d5[\u2207\u22c5\u03bb\u2207\u03d5\u2212\u03c9W\u2032(\u03d5)]\u00a0in\u00a0\u03a9 \\frac{\\partial \\phi}{\\partial t}=M_\\phi[\\nabla \\cdot{} \\lambda \\nabla \\phi -\\omega W'(\\phi)]\\text{ in }\\Omega  \u2202t\u2202\u03d5\u200b=M\u03d5\u200b[\u2207\u22c5\u03bb\u2207\u03d5\u2212\u03c9W\u2032(\u03d5)]\u00a0in\u00a0\u03a9</p> where WWW is a double-well potential defined by: <p>W(\u03d5)=\u03d52(1\u2212\u03d5)2 W(\\phi)=\\phi^2(1-\\phi)^2 W(\u03d5)=\u03d52(1\u2212\u03d5)2</p></p> <p>The objective is to recover the 1D hyperbolic tangent solution</p> <p>\u03d5(r,t=tend)=12+12tanh\u2061[2\u00d7(r\u2212(R/2))\u03f5] \\phi(r,t=t_{end}) = \\frac{1}{2}+\\frac{1}{2}\\tanh\\bigg[2\\times \\frac{(r - (R/2))}{ \\epsilon}\\bigg] \u03d5(r,t=tend\u200b)=21\u200b+21\u200btanh[2\u00d7\u03f5(r\u2212(R/2))\u200b]</p> <p>starting from hyperbolic tangent solution with a thinner interface \u03f50=\u03f5/10\\epsilon_0=\\epsilon/10\u03f50\u200b=\u03f5/10:</p> <p>\u03d5(r,t=0)=12+12tanh\u2061[2\u00d7(r\u2212(R/2)))\u03f50] \\phi(r,t=0) = \\frac{1}{2}+\\frac{1}{2}\\tanh\\bigg[2\\times \\frac{(r - (R/2)))}{ \\epsilon_0}\\bigg] \u03d5(r,t=0)=21\u200b+21\u200btanh[2\u00d7\u03f50\u200b(r\u2212(R/2)))\u200b]</p> <p>Neumann boundary conditions are prescribed on \u0393left\\Gamma_{left}\u0393left\u200b (r=0) and \u0393right\\Gamma_{right}\u0393right\u200b (r=R): <p>n\u22c5\u03bb\u2207\u03d5=0\u00a0on\u00a0\u0393left\u222a\u0393right {\\bf{n}} \\cdot{} \\lambda \\nabla \\phi=0 \\text{ on }\\Gamma_{left} \\cup \\Gamma_{right} n\u22c5\u03bb\u2207\u03d5=0\u00a0on\u00a0\u0393left\u200b\u222a\u0393right\u200b</p></p> <p>For this test, the following parameters are considered:</p> Parameter Symbol Value mobility coefficient M\u03d5M_\\phiM\u03d5\u200b 10\u2212510^{-5}10\u22125 energy gradient coefficient \u03bb\\lambda\u03bb 32\u03c3\u03f5\\frac{3}{2}\\sigma\\epsilon23\u200b\u03c3\u03f5 surface tension \u03c3\\sigma\u03c3 0.060.060.06 interface thickness \u03f5\\epsilon\u03f5 5\u00d710\u221245\\times10^{-4}5\u00d710\u22124 depth of the double-well potential \u03c9\\omega\u03c9 12\u03c3/\u03f512\\frac{\\sigma}/{\\epsilon}12/\u03c3\u200b\u03f5 <ul> <li>Time marching: Euler Implicit scheme, t\u2208[0,50]t\\in[0,50]t\u2208[0,50], \u03b4t=0.25\\delta t=0.25\u03b4t=0.25</li> <li>Spatial discretization: uniform mesh with N=30N=30N=30 elements </li> <li>Double-Well potential: implicit scheme</li> </ul>"},{"location":"Started/HowTo/Simple/index.html#structure-of-an-input-data-file","title":"Structure of an input data file","text":"<p><code>SLOTH</code> provides C++ packages that allows to build multiphysics simulations. </p> <p>What the <code>SLOTH</code> team calls \"input data files\" is actually a <code>main.cpp</code> file mainly composed of four parts:</p> <p>Global structure of an input data file</p> <pre><code>//---------------------------------------\n// 1/ Headers...\n//---------------------------------------\nint main(int argc, char* argv[]) {\n    //---------------------------------------\n    // 1/ Aliases / Parallelism\n    //---------------------------------------\n\n    //---------------------------------------\n    // 2/ Geometry and Spatial discretization\n    //---------------------------------------\n\n    //---------------------------------------\n    // 3/ Multiphysics coupling scheme\n    //---------------------------------------\n\n    //---------------------------------------\n    // 4/ Time discretization\n    //---------------------------------------\n}\n</code></pre>"},{"location":"Started/HowTo/Simple/index.html#common","title":"Headers, Aliases &amp; Parallelism","text":"<p>Headers, aliases and parallelism features are the most general information that can be find in all input data files. </p> <p>There are 3 main headers. </p> <ul> <li><code>kernel/sloth.hpp</code> groups all <code>SLOTH</code> dependencies</li> <li><code>mfem.hpp</code> groups all <code>mfem</code> dependencies</li> <li><code>tests/tests.hpp</code> groups all dependencies useful only for tests</li> </ul> <p>Input data file with headers</p> <pre><code>//---------------------------------------\n// Headers\n//---------------------------------------\n#include \"kernel/sloth.hpp\"\n#include \"mfem.hpp\"  // NOLINT [no include the directory when naming mfem include file]\n#include \"tests/tests.hpp\"\n\nint main(int argc, char* argv[]) {\n\n}\n</code></pre> <p>Aliases facilitate the use of complex C++ types by providing a more concise alternative.  It should be noted that users may define additional aliases. However, those specified in this page pertain to all tests. </p> <p>Each alias employ a template structure for space dimension dependence (see <code>DIM=Test&lt;1&gt;::dim</code> in the example).</p> <p>Input data file with headers and common aliases</p> <pre><code>//---------------------------------------\n// Headers\n//---------------------------------------\n#include \"kernel/sloth.hpp\"\n#include \"mfem.hpp\"  // NOLINT [no include the directory when naming mfem include file]\n#include \"tests/tests.hpp\"\n\nint main(int argc, char* argv[]) {\n    //---------------------------------------\n    // Common aliases\n    //---------------------------------------\n    constexpr int DIM = Test&lt;1&gt;::dim;\n    using FECollection = Test&lt;1&gt;::FECollection;\n    using PSTCollection = Test&lt;1&gt;::PSTCollection;\n    using VARS = Test&lt;1&gt;::VARS;\n    using VAR = Test&lt;1&gt;::VAR;\n    using PST = Test&lt;1&gt;::PST;\n    using SPA = Test&lt;1&gt;::SPA;\n    using BCS = Test&lt;1&gt;::BCS;    \n}\n</code></pre> <p>These aliases both refer to MFEM or <code>SLOTH</code> types used many times in the input data file:</p> Alias Type Description <code>FECollection</code> <code>Test&lt;1&gt;::FECollection</code> Finite Element Space. H1\\cal{H}^1H1 by default (MFEM type) <code>PSTCollection</code> <code>Test&lt;1&gt;::PSTCollection</code> Type of post-processing. Paraview by default (MFEM type) <code>VARS</code> <code>Test&lt;1&gt;::VARS</code> Collection of Variable objects (SLOTH type) <code>VAR</code> <code>Test&lt;1&gt;::VAR</code> Variable object  (SLOTH type) <code>PST</code> <code>Test&lt;1&gt;::PST</code> PostProcessing (SLOTH type) <code>SPA</code> <code>Test&lt;1&gt;::SPA</code> Spatial Discretization (SLOTH type) <code>BCS</code> <code>Test&lt;1&gt;::BCS</code> Boundary Conditions (SLOTH type) <p>SLOTH's ambition is to be able to perform massively parallel computations  while logically retaining the ability to perform sequential computations.</p> <p>Only three lines of code must be defined in each input data file for the MPI and HYPRE libraries.</p> <p>Input data file with headers, common aliases and parallelism features</p> <pre><code>//---------------------------------------\n// Headers\n//---------------------------------------\n#include \"kernel/sloth.hpp\"\n#include \"mfem.hpp\"  // NOLINT [no include the directory when naming `MFEM` include file]\n#include \"tests/tests.hpp\"\n\nint main(int argc, char* argv[]) {\n    //---------------------------------------\n    // Initialize MPI and HYPRE\n    //---------------------------------------\n    mfem::Mpi::Init(argc, argv);\n    mfem::Hypre::Init();\n    //---------------------------------------\n    // Common aliases\n    //---------------------------------------\n    constexpr int DIM = Test&lt;1&gt;::dim;\n    using FECollection = Test&lt;1&gt;::FECollection;\n    using VARS = Test&lt;1&gt;::VARS;\n    using VAR = Test&lt;1&gt;::VAR;\n    using PSTCollection = Test&lt;1&gt;::PSTCollection;\n    using PST = Test&lt;1&gt;::PST;\n    using SPA = Test&lt;1&gt;::SPA;\n    using BCS = Test&lt;1&gt;::BCS;\n\n\n    //---------------------------------------\n    // Finalize MPI\n    //---------------------------------------\n    mfem::Mpi::Finalize();\n}\n</code></pre>"},{"location":"Started/HowTo/Simple/index.html#spatial","title":"Spatial discretization","text":"<p>This part is dedicated the mesh (see Meshing) and the associated boundary conditions (see BoundaryConditions). </p> <p>Regarding the mesh, <code>SLOTH</code> enables to read meshes built with <code>GMSH</code> or to build a Cartesian mesh directly  in <code>MFEM</code>. The order of the Finite Elements and the level of mesh refinement must be also defined. </p> <p>Definition of a Finite Element for <code>SLOTH</code> is made with a C++ object of type <code>SpatialDiscretization</code> or, more specifically for tests, by using the alias <code>SPA</code>.</p> <p>Extract of the input data file with the definition of the mesh</p> <p><pre><code>auto refinement_level = 0;\nauto fe_order = 1;\nauto length = 1.e-3;\nauto nb_fe = 30;\nSPA spatial(\"InlineLineWithSegments\", fe_order, refinement_level, std::make_tuple(nb_fe, length));\n</code></pre> This example considers a 1D Finite Element mesh, without refinement (<code>refinement_level = 0</code>), built directly in <code>MFEM</code>.  The length of the domain is 111 mm (<code>length = 1.e-3</code>), divided into 303030 first order (<code>fe_order = 1</code>) elements (<code>nb_fe = 30</code>).</p> <p>All the functions used to create meshes are detailed in the Meshing section of the user manual. </p> <p>Regarding the boundary conditions, <code>SLOTH</code> enables to prescribe Dirichlet, Neumann and Periodic boundary conditions. </p> <p>Definition of boundary conditions for <code>SLOTH</code> is made with a C++ object of type <code>BoundaryConditions</code> or, more specifically for tests, by using the alias <code>BCS</code>.</p> <p>A <code>BCS</code>object is a collection of C++ objects of type <code>Boundary</code>. Each of them is associated to a geometrical boundary. The number of <code>Boundary</code> objects inside the <code>BCS</code> object must be equal to the total number of geometrical boundary. </p> <p>A <code>Boundary</code> object is defined by</p> <ul> <li>a name (C++ type `std::string'),</li> <li>an index (C++ type <code>int</code>),</li> <li>a type (C++ type `std::string') among \"Dirichlet\", \"Neumann\", \"Periodic\",</li> <li>a value (C++ type <code>double</code>), equal to zero by default.</li> </ul> <p>Extract of the input data file with the mesh and its associated Neumann boundary conditions</p> <p><pre><code>    //---------------------------------------\n    // Meshing &amp; Boundary Conditions\n    //---------------------------------------\n    auto refinement_level = 0;\n    auto fe_order = 1;\n    auto length = 1.e-3;\n    auto nb_fe = 30;\n    SPA spatial(\"InlineLineWithSegments\", fe_order, refinement_level, std::make_tuple(nb_fe, length));\n\n    auto boundaries = {Boundary(\"left\", 0, \"Neumann\", 0.), Boundary(\"right\", 1, \"Neumann\", 0.)};\n    auto bcs = BCS(&amp;spatial, boundaries);\n</code></pre> This example consider Neumann boundary conditions both on the left and on the right of the domain.</p> <p>Different type of boundary conditions can be mixed as detailed in the Boundary Conditions section of the user manual. </p> <p>On the consistency of the indices of the boundaries</p> <p><code>MFEM v4.7</code> provides new features for referring to boundary attribute numbers. Such an improvement is not yet implemented in <code>SLOTH</code>. Consequently, users must take care to the consistency of the indices used in the input data file with the indices defined when building the mesh with <code>GMSH</code>.</p> <p>Input data file with the mesh and the boundary conditions</p> <pre><code>//---------------------------------------\n// Headers\n//---------------------------------------\n#include \"kernel/sloth.hpp\"\n#include \"mfem.hpp\"  // NOLINT [no include the directory when naming mfem include file]\n#include \"tests/tests.hpp\"\n\nint main(int argc, char* argv[]) {\n    //---------------------------------------\n    // Initialize MPI and HYPRE\n    //---------------------------------------\n    mfem::Mpi::Init(argc, argv);\n    mfem::Hypre::Init();\n    //---------------------------------------\n    // Common aliases\n    //---------------------------------------\n    constexpr int DIM = Test&lt;1&gt;::dim;\n    using FECollection = Test&lt;1&gt;::FECollection;\n    using VARS = Test&lt;1&gt;::VARS;\n    using VAR = Test&lt;1&gt;::VAR;\n    using PSTCollection = Test&lt;1&gt;::PSTCollection;\n    using PST = Test&lt;1&gt;::PST;\n    using SPA = Test&lt;1&gt;::SPA;\n    using BCS = Test&lt;1&gt;::BCS;\n    //---------------------------------------\n    // Meshing &amp; Boundary Conditions\n    //---------------------------------------\n    auto refinement_level = 0;\n    auto fe_order = 1;\n    auto length = 1.e-3;\n    auto nb_fe = 30;\n    SPA spatial(\"InlineLineWithSegments\", fe_order, refinement_level, std::make_tuple(nb_fe, length));\n    auto boundaries = {Boundary(\"left\", 0, \"Neumann\", 0.), Boundary(\"right\", 1, \"Neumann\", 0.)};\n    auto bcs = BCS(&amp;spatial, boundaries);\n    //---------------------------------------\n    // Finalize MPI\n    //---------------------------------------\n    mfem::Mpi::Finalize();\n}\n</code></pre>"},{"location":"Started/HowTo/Simple/index.html#coupling","title":"Multiphysics coupling scheme","text":"<p>This part is the core of the input data file with the definition of the targeted physical problems (eg. equations, variational formulations, variables, coefficients) gathered inside a <code>Coupling</code> object. </p> <p>This implies many C++ objects designed specifically for <code>SLOTH</code>.  The main one is the <code>Problem</code> object defined as a collection of C++ objects of interest for <code>SLOTH</code>:</p> <ul> <li>a <code>Variables</code> object,</li> <li>an <code>Operator</code> object, </li> <li>a <code>PostProcessing</code> object,</li> <li>a <code>PhysicalConvergence</code> object. </li> </ul> <p>Regarding the <code>Variables</code>, <code>SLOTH</code> differentiates between so-called primary variables, which are solved directly by the problem (eg. the order parameter for the Allen-Cahn equation, the order parameter and the chemical potential for the Cahn-Hilliard equation), and secondary variables, which are derived from another problem to ensure multiphysics coupling (eg. the order parameter in the heat transfer equation, the temperature in the Allen-Cahn equation). </p> <p>Despite their different purposes, the definition of primary and auxiliary variables are consistent and made with a C++ object of type <code>Variables</code> (see the alias <code>VARS</code>).  <code>Variables</code> is simply a collection of <code>Variable</code> object (see the alias <code>VAR</code>) defined by:</p> <ul> <li>the spatial discretisation (ie. the <code>SPA</code>object), </li> <li>a set of boundary conditions (ie the <code>BCS</code> object), </li> <li>a name (C++ type <code>std::string</code>), </li> <li>a storage depth level (C++ type <code>int</code>), </li> <li>an initial condition,</li> <li>an analytical solution (optional). </li> </ul> <p>Definition of variables with an analytical solution</p> <p>The presence of an analytical solution automatically enables the calculation of the  L2L^2L2 error over the domain. </p> <p>Whether it's an initial condition or an analytical solution, the users can define them with a constant, a C++ object of type <code>std::function</code> or a C++ object of type <code>AnalyticalFunctions</code>. </p> <p>It is recommended to read the page dedicated to <code>Variables</code> in the user manual for more details about the use and the different definitions of this <code>SLOTH</code> object.</p> <p><code>AnalyticalFunctions</code> enable to use pre-defined mathematical functions currently used in the studies conducted with <code>SLOTH</code>. A comprehensive overview of the analytical functions available in <code>SLOTH</code> is provided in a dedicated page of the user manual. If the mathematical expression is not yet available, the users can define it with a C++ object of type <code>std::function</code>.</p> <p>Extract of the input data file with Variables</p> <p><pre><code>    //---------------------------------------\n    // Multiphysics coupling scheme\n    //---------------------------------------     \n    //--- Variables\n    const auto&amp; center_x = 0.;\n    const auto&amp; a_x = 1.;\n    const auto&amp; thickness = 5.e-5;\n    const auto&amp; radius = 5.e-4;\n\n    std::string variable_name = \"phi\";\n    int level_of_storage= 2;\n\n    auto initial_condition = AnalyticalFunctions&lt;DIM&gt;(AnalyticalFunctionsType::from(\"HyperbolicTangent\"), center_x, a_x, 2.*epsilon, radius);\n    auto analytical_solution = AnalyticalFunctions&lt;DIM&gt;(AnalyticalFunctionsType::from(\"HyperbolicTangent\"), center_x, a_x, epsilon, radius);\n    auto vars = VARS(VAR(&amp;spatial, bcs, variable_name, level_of_storage, initial_condition, analytical_solution));\n</code></pre> This example defines a single primary variable, named \"phi\" with two levels of storage.  The initial condition and the analytical solution are of the hyperbolic tangent type.</p> <p>Another class of major C++ objects for <code>SLOTH</code> is <code>Operator</code>.  These objects allow the solution of the algebraic system resulting from the discretization of the (non-linear) equations.  For each of them, the users can find a stationary and a transient version.  This is detailed in the <code>Operator</code> page of the user manual. Although the input arguments provided to the <code>Operator</code> object are of interest, the focus is rather on the definition of the C++ object itself, which requires the input of the variational formulation of the equations.  This specificity is implemented on the basis of <code>NonLinearFormIntegrators</code> objects, also detailed in the user manual in the <code>Integrators</code> page.  The definition of the integrators obviously depends on the targeted problem.  In the present example, the variational formulation is defined by using the <code>AllenCahnNLFormIntegrator</code> object.  This is the most general form of integrator for Allen-Cahn problems.</p> <p>Extract of the input data file with Operators and Integrators</p> <pre><code>    //--- Integrator : alias definition for the sake of clarity\n    using NLFI = AllenCahnNLFormIntegrator&lt;VARS, ThermodynamicsPotentialDiscretization::Implicit, ThermodynamicsPotentials::W, Mobility::Constant&gt;;\n\n    //--- Operator definition\n    //  Interface thickness\n    const auto&amp; epsilon(5.e-4);\n    // Interfacial energy\n    const auto&amp; sigma(6.e-2);\n    // Two-phase mobility\n    const auto&amp; mob(1.e-5);\n    const auto&amp; lambda = 3. * sigma * epsilon / 2.;\n    const auto&amp; omega = 12. * sigma / epsilon;\n    auto params = Parameters(Parameter(\"epsilon\", epsilon), Parameter(\"sigma\", sigma), Parameter(\"lambda\", lambda), Parameter(\"omega\", omega));\n\n    AllenCahnOperator&lt;FECollection, DIM, NLFI&gt; oper(&amp;spatial, params, TimeScheme::EulerImplicit);\n</code></pre> <p>Use of <code>Parameters</code> and <code>Parameter</code> objects</p> <p><code>Parameters</code> is a C++ object designed for <code>SLOTH</code> and defined as a collection of <code>Parameter</code> objects. The latter is also a C++ object specially developed for <code>SLOTH</code>.  It enables the definition of a variable which can be of different C++ types. It is based on the <code>std::variant</code> type. Users are referred to the <code>Parameters</code> page in the user manual for more details about the definition and the use of these objects.</p> <p>The results of <code>SLOTH</code> simulations can be exported to VTK format and can be read with Paraview. This is possible by using the C++ object <code>PSTCollection</code> or, more specifically for tests, by using the alias <code>PST</code>.  This C++ object requires the knowledge of the mesh and a number of parameters to define, at least, the directories in which the results are stored and the frequency of storage.  All these parameters are detailed in the page PostProcessing.  By default, all primary variables associated with a <code>SLOTH</code> <code>Problem</code> are saved.</p> <p>Extract of the input data file with PostProcessing</p> <p><pre><code>    //--- Post-Processing \n    const std::string&amp; main_folder_path = \"Saves\";\n    std::string calculation_path = \"AllenCahn\";\n    const auto&amp; frequency = 1;\n    auto pst_parameters = Parameters(Parameter(\"main_folder_path\", main_folder_path), Parameter(\"calculation_path\", calculation_path), Parameter(\"frequency\", frequency));\n    auto pst = PST(&amp;spatial, pst_parameters);\n</code></pre> In this example, the results will be saved in the <code>Saves/AllenCahn</code> directory (see <code>Parameter(\"main_folder_path\", main_folder_path)</code> and  <code>Parameter(\"calculation_path\", calculation_path)</code>), at each time-step (see <code>Parameter(\"frequency\", frequency)</code>).</p> <p>The last object needed to define a <code>SLOTH</code> <code>Problem</code> is the physical convergence criterion.  It corresponds to the C++ object <code>PhysicalConvergence</code>. Relative and absolute criteria are available. It is worth mentioning that this object is disabled. It will be enabled when fixed point algorithm and automatic time-step splitting are integrated.</p> <p>Input data file with PhysicalConvergence</p> <pre><code>    //--- Physical Convergence\n    const double crit_cvg = 1.e-12;\n    PhysicalConvergence convergence(ConvergenceType::ABSOLUTE_MAX, crit_cvg);\n</code></pre> <p>At this stage,  the <code>SLOTH</code> <code>Problem</code> can be defined and, as previously explained, collected in a <code>Coupling</code> object.  This is illustrated in the following example (see <code>Problem&lt;OPE, VARS, PST&gt; ac_problem</code> and  <code>Coupling(\"Main coupling\", ac_problem)</code>). </p> <p>Input data file with Variables, Operators and Integrators, Post-Processing and Physical Convergence</p> <p><pre><code>//---------------------------------------\n// Headers\n//---------------------------------------\n#include \"kernel/sloth.hpp\"\n#include \"mfem.hpp\"  // NOLINT [no include the directory when naming mfem include file]\n#include \"tests/tests.hpp\"\n\nint main(int argc, char* argv[]) {\n    //---------------------------------------\n    // Initialize MPI and HYPRE\n    //---------------------------------------\n    mfem::Mpi::Init(argc, argv);\n    mfem::Hypre::Init();\n    //---------------------------------------\n    // Common aliases\n    //---------------------------------------\n    constexpr int DIM = Test&lt;1&gt;::dim;\n    using FECollection = Test&lt;1&gt;::FECollection;\n    using VARS = Test&lt;1&gt;::VARS;\n    using VAR = Test&lt;1&gt;::VAR;\n    using PSTCollection = Test&lt;1&gt;::PSTCollection;\n    using PST = Test&lt;1&gt;::PST;\n    using SPA = Test&lt;1&gt;::SPA;\n    using BCS = Test&lt;1&gt;::BCS;\n    //---------------------------------------\n    // Meshing &amp; Boundary Conditions\n    //---------------------------------------\n    auto refinement_level = 0;\n    auto fe_order = 1;\n    auto length = 1.e-3;\n    auto nb_fe = 30;\n    SPA spatial(\"InlineLineWithSegments\", fe_order, refinement_level, std::make_tuple(nb_fe, length));\n    auto boundaries = {Boundary(\"left\", 0, \"Neumann\", 0.), Boundary(\"right\", 1, \"Neumann\", 0.)};\n    auto bcs = BCS(&amp;spatial, boundaries);\n\n    //---------------------------------------\n    // Multiphysics coupling scheme\n    //---------------------------------------     \n    //--- Variables\n    const auto&amp; center_x = 0.;\n    const auto&amp; a_x = 1.;\n    const auto&amp; thickness = 5.e-5;\n    const auto&amp; radius = 5.e-4;\n\n    std::string variable_name = \"phi\";\n    int level_of_storage= 2;\n\n    auto initial_condition = AnalyticalFunctions&lt;DIM&gt;(AnalyticalFunctionsType::from(\"HyperbolicTangent\"), center_x, a_x, 2.*epsilon, radius);\n    auto analytical_solution = AnalyticalFunctions&lt;DIM&gt;(AnalyticalFunctionsType::from(\"HyperbolicTangent\"), center_x, a_x, epsilon, radius);\n    auto vars = VARS(VAR(&amp;spatial, bcs, variable_name, level_of_storage, initial_condition, analytical_solution));\n\n    //--- Integrator : alias definition for the sake of clarity\n    using NLFI = AllenCahnNLFormIntegrator&lt;VARS, ThermodynamicsPotentialDiscretization::Implicit, ThermodynamicsPotentials::W, Mobility::Constant&gt;;\n\n    //--- Operator definition\n    //  Interface thickness\n    const auto&amp; epsilon(5.e-4);\n    // Interfacial energy\n    const auto&amp; sigma(6.e-2);\n    // Two-phase mobility\n    const auto&amp; mob(1.e-5);\n    const auto&amp; lambda = 3. * sigma * epsilon / 2.;\n    const auto&amp; omega = 12. * sigma / epsilon;\n    auto params = Parameters(Parameter(\"epsilon\", epsilon), Parameter(\"sigma\", sigma), Parameter(\"lambda\", lambda), Parameter(\"omega\", omega));\n\n    AllenCahnOperator&lt;FECollection, DIM, NLFI&gt; oper(&amp;spatial, params, TimeScheme::EulerImplicit);\n\n    //--- Post-Processing \n    const std::string&amp; main_folder_path = \"Saves\";\n    std::string calculation_path = \"AllenCahn\";\n    const auto&amp; frequency = 1;\n    auto pst_parameters = Parameters(Parameter(\"main_folder_path\", main_folder_path), Parameter(\"calculation_path\", calculation_path), Parameter(\"frequency\", frequency));\n    auto pst = PST(&amp;spatial, pst_parameters);\n\n    //--- Physical Convergence\n    const double crit_cvg = 1.e-12;\n    PhysicalConvergence convergence(ConvergenceType::ABSOLUTE_MAX, crit_cvg);\n\n    //-----------------------\n    // Problem\n    //-----------------------\n    Problem&lt;OPE, VARS, PST&gt; ac_problem(oper, vars, pst, convergence);\n    //-----------------------\n    // Coupling\n    //-----------------------\n    auto main_coupling = Coupling(\"Main coupling\", ac_problem);\n\n    //---------------------------------------\n    // Finalize MPI\n    //---------------------------------------\n    mfem::Mpi::Finalize();\n}\n</code></pre> In this example, a coupling, labelled <code>Main coupling</code>, is defined with only one <code>SLOTH</code> <code>Problem</code> associated with the solution of Allen-Cahn equation.</p> <p>Users are referred to the Problems and Coupling page of the user manual for more details about the available <code>SLOTH</code> <code>Problem</code> and how to use them.</p>"},{"location":"Started/HowTo/Simple/index.html#time","title":"Time discretization","text":"<p>Time discretization is the last main part of an input data file.  It corresponds to the C++ object <code>TimeDiscretization</code> defined as a number of parameters and the <code>Coupling</code> objects specially designed for the current <code>SLOTH</code> simulation. Among these parameters, there are the initial time, the final time and the uniform value of the time-step.  The method <code>solve</code> must be explicitly called to run the calculation. This is detailed in the <code>Time</code> page of the user manual.</p> <p>Extract of the input data file with TimeDiscretization</p> <p><pre><code>    //---------------------------------------\n    // Time discretization\n    //--------------------------------------- \n    const auto&amp; t_initial = 0.0;\n    const auto&amp; t_final = 50.0;\n    const auto&amp; dt = 0.01;\n    auto time_parameters = Parameters(Parameter(\"initial_time\", t_initial), Parameter(\"final_time\", t_final), Parameter(\"time_step\", dt));\n    auto time = TimeDiscretization(time_parameters, cc);\n\n    time.solve();\n</code></pre> In this example, the simulation is performed during 505050 s with a time-step equal to 0.010.010.01 s.</p>"},{"location":"Started/HowTo/Simple/index.html#comprehensive-input-data-file","title":"Comprehensive input data file","text":"<p>Input data file with Variables, Operators and Integrators, Post-Processing, Physical Convergence and Time Discretization</p> <pre><code>//---------------------------------------\n// Headers\n//---------------------------------------\n#include \"kernel/sloth.hpp\"\n#include \"mfem.hpp\"  // NOLINT [no include the directory when naming mfem include file]\n#include \"tests/tests.hpp\"\n\nint main(int argc, char* argv[]) {\n    //---------------------------------------\n    // Initialize MPI and HYPRE\n    //---------------------------------------\n    mfem::Mpi::Init(argc, argv);\n    mfem::Hypre::Init();\n    //---------------------------------------\n    // Common aliases\n    //---------------------------------------\n    constexpr int DIM = Test&lt;1&gt;::dim;\n    using FECollection = Test&lt;1&gt;::FECollection;\n    using VARS = Test&lt;1&gt;::VARS;\n    using VAR = Test&lt;1&gt;::VAR;\n    using PSTCollection = Test&lt;1&gt;::PSTCollection;\n    using PST = Test&lt;1&gt;::PST;\n    using SPA = Test&lt;1&gt;::SPA;\n    using BCS = Test&lt;1&gt;::BCS;\n    //---------------------------------------\n    // Meshing &amp; Boundary Conditions\n    //---------------------------------------\n    auto refinement_level = 0;\n    auto fe_order = 1;\n    auto length = 1.e-3;\n    auto nb_fe = 30;\n    SPA spatial(\"InlineLineWithSegments\", fe_order, refinement_level, std::make_tuple(nb_fe, length));\n    auto boundaries = {Boundary(\"left\", 0, \"Neumann\", 0.), Boundary(\"right\", 1, \"Neumann\", 0.)};\n    auto bcs = BCS(&amp;spatial, boundaries);\n\n    //---------------------------------------\n    // Multiphysics coupling scheme\n    //---------------------------------------     \n    //--- Variables\n    const auto&amp; center_x = 0.;\n    const auto&amp; a_x = 1.;\n    const auto&amp; thickness = 5.e-5;\n    const auto&amp; radius = 5.e-4;\n\n    std::string variable_name = \"phi\";\n    int level_of_storage= 2;\n\n    auto initial_condition = AnalyticalFunctions&lt;DIM&gt;(AnalyticalFunctionsType::from(\"HyperbolicTangent\"), center_x, a_x, 2.*epsilon, radius);\n    auto analytical_solution = AnalyticalFunctions&lt;DIM&gt;(AnalyticalFunctionsType::from(\"HyperbolicTangent\"), center_x, a_x, epsilon, radius);\n    auto vars = VARS(VAR(&amp;spatial, bcs, variable_name, level_of_storage, initial_condition, analytical_solution));\n\n    //--- Integrator : alias definition for the sake of clarity\n    using NLFI = AllenCahnNLFormIntegrator&lt;VARS, ThermodynamicsPotentialDiscretization::Implicit, ThermodynamicsPotentials::W, Mobility::Constant&gt;;\n\n    //--- Operator definition\n    //  Interface thickness\n    const auto&amp; epsilon(5.e-4);\n    // Interfacial energy\n    const auto&amp; sigma(6.e-2);\n    // Two-phase mobility\n    const auto&amp; mob(1.e-5);\n    const auto&amp; lambda = 3. * sigma * epsilon / 2.;\n    const auto&amp; omega = 12. * sigma / epsilon;\n    auto params = Parameters(Parameter(\"epsilon\", epsilon), Parameter(\"sigma\", sigma), Parameter(\"lambda\", lambda), Parameter(\"omega\", omega));\n\n    AllenCahnOperator&lt;FECollection, DIM, NLFI&gt; oper(&amp;spatial, params, TimeScheme::EulerImplicit);\n\n    //--- Post-Processing \n    const std::string&amp; main_folder_path = \"Saves\";\n    std::string calculation_path = \"AllenCahn\";\n    const auto&amp; frequency = 1;\n    auto pst_parameters = Parameters(Parameter(\"main_folder_path\", main_folder_path), Parameter(\"calculation_path\", calculation_path), Parameter(\"frequency\", frequency));\n    auto pst = PST(&amp;spatial, pst_parameters);\n\n    //--- Physical Convergence\n    const double crit_cvg = 1.e-12;\n    PhysicalConvergence convergence(ConvergenceType::ABSOLUTE_MAX, crit_cvg);\n\n    //-----------------------\n    // Problem\n    //-----------------------\n    Problem&lt;OPE, VARS, PST&gt; ac_problem(oper, vars, pst, convergence);\n    //-----------------------\n    // Coupling\n    //-----------------------\n    auto main_coupling = Coupling(\"Main coupling\", ac_problem);\n\n    //---------------------------------------\n    // Time discretization\n    //--------------------------------------- \n    const auto&amp; t_initial = 0.0;\n    const auto&amp; t_final = 50.0;\n    const auto&amp; dt = 0.01;\n    auto time_parameters = Parameters(Parameter(\"initial_time\", t_initial), Parameter(\"final_time\", t_final), Parameter(\"time_step\", dt));\n    auto time = TimeDiscretization(time_parameters, cc);\n\n    time.solve();\n\n    //---------------------------------------\n    // Finalize MPI\n    //---------------------------------------\n    mfem::Mpi::Finalize();\n}\n</code></pre>"},{"location":"Started/HowTo/Tutorials/index.html","title":"Tutorials","text":""},{"location":"Started/HowTo/Tutorials/tuto1.html","title":"Profiling of the simulation","text":""},{"location":"Started/Installation/index.html","title":"Installation guide","text":"<p><code>SLOTH</code> is written in <code>C++17</code>. It can be built under Linux and MacOS using <code>CMake</code>.  The main prerequisite is the <code>MFEM</code> Finite Element library developed in C++ by LLNL<sup>1</sup>.</p> <p><code>MFEM</code> can be installed in several ways but the use of <code>spack</code> on Linux and <code>Homebrew</code>on MacOS is recommended for sake of simplicity.</p> <p>Installing <code>SLOTH</code> therefore consists of first installing <code>MFEM</code> and compiling <code>SLOTH</code>.  The basic procedure is then provided for the Linux platform and the MacOs platform, but also for supercomputers where <code>SLOTH</code> is intended to be used.</p> <ol> <li> <p>Robert Anderson, Julian Andrej, Andrew Barker, Jamie Bramwell, Jean-Sylvain Camier, Jakub Cerveny, Veselin Dobrev, Yohann Dudouit, Aaron Fisher, Tzanio Kolev, and others. Mfem: a modular finite element methods library. Computers &amp; Mathematics with Applications, 81:42\u201374, 2021.\u00a0\u21a9</p> </li> </ol>"},{"location":"Started/Installation/cluster.html","title":"Cluster","text":""},{"location":"Started/Installation/cluster.html#installing-sloth-on-supercomputers-without-internet-access","title":"Installing SLOTH On Supercomputers Without Internet Access","text":"<p>This guide provides detailed steps to install SLOTH on a supercomputer without internet access using provided scripts. It includes using Spack for package management and compiling dependencies required by SLOTH.</p> <p>Installing SLOTH on a supercomputer without internet access involves preparing the environment, downloading necessary components, creating a local Spack mirror, and building SLOTH with all dependencies.</p>"},{"location":"Started/Installation/cluster.html#use-and-adapt-scripts","title":"Use And Adapt Scripts","text":"<p>The installation is performed in two main parts using the scripts provided below:</p> <ol> <li><code>sloth-topaze-part1.sh</code>: Prepares the environment and creates an archive of necessary components.</li> <li><code>sloth-topaze-part2.sh</code>: Sets up Spack and compiles SLOTH on the target supercomputer.</li> </ol> <p>Make sure to adapt the environment variables in the scripts (e.g., <code>MY_LOG</code>, <code>DEST_DIR</code>) to your specific user settings.</p> <p>On your local machine:</p> <pre><code>source sloth-topaze-part1.sh\n</code></pre> <p>On your distant machine (Topaze in our example)</p> <pre><code>sloth-topaze-part2.sh\n</code></pre>"},{"location":"Started/Installation/cluster.html#part-1-preparing-the-environment-sloth-topaze-part1sh","title":"Part 1: Preparing the Environment (<code>sloth-topaze-part1.sh</code>)","text":"<p>This script is designed to be run on a local machine with internet access. It sets up the environment, clones necessary repositories, prepares Spack, and packages everything into an archive for transfer to the supercomputer.</p>"},{"location":"Started/Installation/cluster.html#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":"<ol> <li>Define Root and Working Directories: <pre><code>export ROOT_DIR=$PWD\nmkdir -p sloth-topaze-dir &amp;&amp; cd sloth-topaze-dir\nexport WORK_DIR=$ROOT_DIR/sloth-topaze-dir\nexport MY_LOG=your_login      # Replace with your Topaze login\nexport DEST_DIR=/path/to/destination # Replace with your destination directory\n</code></pre></li> <li><code>ROOT_DIR</code> is set to the current directory.</li> <li>Creates a subdirectory <code>sloth-topaze-dir</code> where all operations will occur.</li> <li><code>WORK_DIR</code> is set to the path of <code>sloth-topaze-dir</code>.</li> <li> <p><code>MY_LOG</code> and <code>DEST_DIR</code> are placeholders for your supercomputer login and destination directory. You need to replace these with your actual login and path on the supercomputer.</p> </li> <li> <p>Clone Spack Repository: <pre><code>echo \"Getting Spack ...\"\nif [ ! -d \"spack\" ]; then\n    git clone https://github.com/spack/spack.git\nfi\nexport SPACK_ROOT=$PWD/spack\nrm -r ~/.spack\nsource ${SPACK_ROOT}/share/spack/setup-env.sh\n</code></pre></p> </li> <li>Clones Spack from GitHub.</li> <li>Sets <code>SPACK_ROOT</code> to the path of the cloned Spack directory.</li> <li>Removes any existing <code>.spack</code> configuration to ensure a clean setup.</li> <li> <p>Sources the Spack environment to set up paths and commands for use.</p> </li> <li> <p>Clone SLOTH Repository: <pre><code>echo \"Getting PLEIADES/SLOTH ...\"\nif [ ! -d \"sloth\" ]; then\n    git clone [https://www-git-cad.intra.cea.fr/DEC/collaboratif/ci230846/DEV_PROJECT/sloth.git](https://github.com/Collab4Sloth/SLOTH.git)\nfi\n</code></pre></p> </li> <li> <p>Similar to Spack, this step clones the SLOTH repository if it doesn't already exist in the working directory.</p> </li> <li> <p>Create a Spack Bootstrap Mirror: <pre><code>spack bootstrap mirror --binary-packages my_bootstrap\n</code></pre></p> </li> <li> <p>Creates a bootstrap mirror that includes binary packages of the basic build tools that Spack needs to work offline.</p> </li> <li> <p>Create a Specific Spack Mirror for Dependencies: <pre><code>spack mirror create -d mirror-mfem -D gcc@11.2.0 mfem+mpi+debug+openmp+petsc+strumpack+suite-sparse+sundials+superlu-dist%gcc@11.2.0\n</code></pre></p> </li> <li>Creates a mirror named <code>mirror-mfem</code> for all specified dependencies (<code>mfem</code>, <code>petsc</code>, etc.), ensuring that Spack can access these packages without internet access on the supercomputer.</li> <li> <p>You can add extra packages here.</p> </li> <li> <p>Package and Transfer Files: <pre><code>cd $ROOT_DIR\ntar cvf archive.tar.gz sloth-topaze-dir/\nscp archive.tar.gz $MY_LOG@topaze.ccc.cea.fr:$DEST_DIR/\n</code></pre></p> </li> <li>Archives the entire <code>sloth-topaze-dir</code> directory into <code>archive.tar.gz</code>.</li> <li>Uses <code>scp</code> to securely copy this archive to the specified destination directory on the supercomputer. Replace <code>topaze.ccc.cea.fr</code> with the appropriate hostname if needed.</li> </ol>"},{"location":"Started/Installation/cluster.html#part-2-setting-up-and-building-sloth-sloth-topaze-part2sh","title":"Part 2: Setting Up and Building SLOTH (<code>sloth-topaze-part2.sh</code>)","text":"<p>This script is run on the supercomputer. It unpacks the archive, sets up the Spack environment, configures Spack to work offline, and builds SLOTH with all required dependencies.</p>"},{"location":"Started/Installation/cluster.html#step-by-step-breakdown_1","title":"Step-by-Step Breakdown","text":"<ol> <li>Define Directories: <pre><code>export DEST_DIR=$PWD\nexport WORK_DIR=$DEST_DIR/sloth-topaze-dir\n</code></pre></li> <li><code>DEST_DIR</code> is set to the current working directory (where the archive was transferred).</li> <li> <p><code>WORK_DIR</code> points to the <code>sloth-topaze-dir</code> directory inside <code>DEST_DIR</code>.</p> </li> <li> <p>Clean Up and Extract the Archive: <pre><code>rm -r ~/.spack\ncd $DEST_DIR\ntar xvf archive.tar.gz\ncd $WORK_DIR\n</code></pre></p> </li> <li>Removes any existing Spack configuration (<code>~/.spack</code>) to ensure a fresh environment setup.</li> <li> <p>Extracts the archive (<code>archive.tar.gz</code>) containing all previously prepared files.</p> </li> <li> <p>Set Up Spack Environment: <pre><code>source $WORK_DIR/spack/share/spack/setup-env.sh\nspack bootstrap reset -y\nspack bootstrap add --scope=site --trust local-binaries $PWD/my_bootstrap/metadata/binaries/\nspack bootstrap disable --scope=site github-actions-v0.5\nspack bootstrap disable --scope=site github-actions-v0.4\nspack bootstrap disable --scope=site spack-install\nspack bootstrap root $PWD/spack/bootstrap\nspack bootstrap now\nspack bootstrap status\n</code></pre></p> </li> <li>Sources the Spack environment to set up the paths and commands.</li> <li>Resets Spack\u2019s bootstrap configuration and adds the local bootstrap mirror (<code>my_bootstrap</code>) created earlier, ensuring all dependencies are fetched locally.</li> <li>Disables unnecessary bootstrap sources (<code>github-actions-v0.5</code>, etc.) to avoid any attempt to connect online.</li> <li> <p>Sets the root path for Spack\u2019s bootstrap environment and checks the status.</p> </li> <li> <p>Set Compiler and Environment Variables: <pre><code>export CC='gcc'\nexport CXX='g++'\nexport FC='mpifort'\nexport OMPI_CC='gcc'\nexport OMPI_CXX='g++'\nexport OMPI_FC='gfortran'\n</code></pre></p> </li> <li>Specifies compilers for C, C++, and Fortran, ensuring the correct toolchain is used during the build.</li> <li> <p>Sets OpenMPI environment variables to link the compilers correctly.</p> </li> <li> <p>Load Required Modules and Add Spack Mirror: <pre><code>module load gnu/11.2.0 mpi cmake/3.29.6 \nspack mirror add SLOTH $WORK_DIR/mirror-mfem/\nspack compiler find\nspack external find openmpi\nspack external find cmake\nspack external find openssh\n</code></pre></p> </li> <li>Loads necessary modules (<code>gnu</code>, <code>mpi</code>, <code>cmake</code>) to provide the required tools and compilers.</li> <li>Adds the previously created Spack mirror (<code>mirror-mfem</code>) so that dependencies are fetched from the local mirror instead of the internet.</li> <li> <p>Detects and registers available compilers and external software (e.g., <code>openmpi</code>, <code>cmake</code>, <code>openssh</code>) within Spack.</p> </li> <li> <p>Install Dependencies and Build SLOTH: <pre><code>spack install gcc@11.2.0 mfem+mpi+debug+openmp+petsc+strumpack+suite-sparse+sundials+superlu-dist%gcc@11.2.0\ncd $WORK_DIR/sloth\nmkdir build &amp;&amp; cd build\nspack load mfem\nspack load metis\nexport HYPRE_DIR=`spack location -i hypre`\nexport MPI_DIR=`spack location -i mpi`\nexport METIS_DIR=`spack location -i metis`\n\ncmake .. -DMFEM_USE_PETSC=ON -DPETSC_DIR=${PETSC_DIR} -DPETSC_ARCH=\"\" -DPETSC_INCLUDES=${PETSC_DIR}/include -DPETSC_LIBRARIES=${PETSC_DIR}/lib -DPETSC_EXECUTABLE_RUNS=${PETSC_DIR}/bin\nmake -j 10\nctest\n</code></pre></p> </li> <li>Installs GCC and other specified dependencies from the local mirror without accessing the internet.</li> <li>Sets up the build directory within the SLOTH repository (<code>build</code>).</li> <li>Loads required dependencies (<code>mfem</code>, <code>metis</code>) to ensure they are available for the build process.</li> <li>Sets environment variables to locate specific dependency installations.</li> <li>Configures SLOTH with <code>cmake</code>, pointing to relevant dependencies (<code>PETSC</code>, etc.), and builds the software using <code>make</code>.</li> <li>Runs tests with <code>ctest</code> to verify the build.</li> </ol>"},{"location":"Started/Installation/cluster.html#run-your-simulation-on-topaze","title":"Run Your Simulation On Topaze","text":"<p>Script example of a simulation running on milan partition over 8192 mpi processes with a duration limit of about 24 hours:</p> <pre><code>#!/bin/bash\n#MSUB -r sloth_big_run\n#MSUB -n 8192\n#MSUB -c 1\n#MSUB -T 86000\n#MSUB -m scratch\n#MSUB -o sloth_big_run_%I.o\n#MSUB -e sloth_big_run_%I.e\n#MSUB -q milan\n\nset -x\nexport OMP_NUM_THREADS=1\nccc_mprun ./test3D\n</code></pre>"},{"location":"Started/Installation/linux.html","title":"On Linux with Spack","text":"<p>A straightforward way to install MFEM is to use spack.</p> <p>Installing spack</p> <p>To install spack on Linux, the first step consists in cloning and loading it into a <code>$SPACK</code> directory (see spack for more details.)</p> <p>Assuming <code>spack</code> well installed into the <code>$SPACK</code> directory, the following command enables to install MFEM with right additional packages:</p> <pre><code>$SPACK/share/spack/setup-env.sh\n\nspack install mfem+mpi+suite-sparse+sundials+superlu-dist\n</code></pre> <p>Installing a given version of MFEM</p> <p>The user is free to install different version of MFEM.  By default, the last released is considered. otherwise, \"@version\" must be added at the end of the <code>spack</code> command.</p> <p>Once MFEM is installed, priori to compile SLOTH, MFEM must be loaded and several environment variables must be defined:</p> <pre><code>   spack load mfem\n\n   export HYPRE_DIR=$(spack location -i hypre)\n\n   export MPI_DIR=$(spack location -i mpi)\n\n   export METIS_DIR=$(spack location -i metis)\n</code></pre> <p>On the use of the  <code>envSloth.sh</code> configuration file</p> <p>These definitions are written into the configuration file <code>envSloth.sh</code> located in the root directory of the SLOTH repository.  The use of this file is recommended to load the MFEM environment before compilling SLOTH.</p> <ul> <li>Load the SLOTH configuration file: <pre><code>source ../envSloth.sh [OPTIONS] \n</code></pre> where [OPTIONS] are: <pre><code>    --release to build with Release compiler options \n\n    --optim to build with Optim compiler options \n\n    --debug to build with Debug compiler options \n\n    --coverage to build with Coverage compiler options \n\n    --external to built SLOTH with an external package\n</code></pre></li> </ul> <p>By default, SLOTH is built with release compiler options.</p> <ul> <li>Finally, compile  <pre><code>make -j N \n</code></pre> with N the number of jobs.</li> </ul>"},{"location":"Started/Installation/mac.html","title":"On MacOS with Homebrew","text":"<p>Following the MFEM website, the simplest way to install MFEM on MacOS consists in using the package manager Homebrew (see https://brew.sh for more details):</p> <pre><code>brew install mfem\n</code></pre> <p>Installing a given version of MFEM</p> <p>By default, this MFEM installation depends on hypre, metis, openblas, suite-sparse.</p> <p>It is possible rebuild MFEM with additional dependencies (see https://formulae.brew.sh/formula/mfem#default for more details).    To do this,  </p> <ul> <li>Get the .rb file : run <code>brew edit mfem</code> to open the default rb file or get it from Github</li> <li>Add your dependencies with <code>depends_on</code> directive. Here, let us consider the <code>petsc</code> dependency:</li> </ul> <pre><code>depends_on \"cmake\" =&gt; :build\ndepends_on \"hypre\"       \ndepends_on \"metis\"       \ndepends_on \"openblas\"\ndepends_on \"suite-sparse\"\ndepends_on \"petsc\"\n</code></pre> <ul> <li>Save the file in the directory and run the following command:</li> </ul> <pre><code>brew install --formula mfem.rb\n</code></pre> <p>Installation with petsc can be checked by editing once again the mfem.rb file. petsc must be mentioned as default dependency. </p> <p>Each dependency can be installed easily using homebrew. </p> <p>Once MFEM is installed, priori to compile SLOTH several environment variables must be defined:</p> <pre><code>export MFEM_DIR=$(echo `brew --prefix mfem`)\n\nexport MPI_DIR=$(echo `brew --prefix open-mpi`)\n\nexport HYPRE_DIR=$(echo `brew --prefix hypre`)\n\nexport METIS_DIR=$(echo `brew --prefix metis`)\n</code></pre> <p>On the use of the  <code>envSloth.sh</code> configuration file</p> <p>These definitions are written into the configuration file <code>envSloth.sh</code> located in the root directory of the SLOTH repository.  The use of this file is recommended to load the MFEM environment before compilling SLOTH.</p> <ul> <li>Load the SLOTH configuration file: <pre><code>source ../envSloth.sh [OPTIONS] \n</code></pre> where [OPTIONS] are: <pre><code>    --release to build with Release compiler options \n\n    --optim to build with Optim compiler options \n\n    --debug to build with Debug compiler options \n\n    --coverage to build with Coverage compiler options \n\n    --external to built SLOTH with an external package\n</code></pre></li> </ul> <p>By default, SLOTH is built with release compiler options.</p> <ul> <li>Finally, compile  <pre><code>make -j N \n</code></pre> with N the number of jobs.</li> </ul>"},{"location":"Started/Installation/sources.html","title":"On Linux from source files","text":"<p>The following installation procedure describes how to install <code>SLOTH</code> from source files. </p> <p>It is assumed that the user has a Unix environment with a recent GCC compiler (C++20 compatible) and MPI libraries. Obviously, Git is also needed to clone source files.</p> <p>The following procedure is mainly based on the installation procedure of a parallel MPI version of <code>MFEM</code>.  Only the installation of SuiteSparse will be added.</p>"},{"location":"Started/Installation/sources.html#getting-source-files","title":"Getting source files","text":"<p>The first step consists in cloning <code>MFEM</code>, <code>METIS</code>, <code>HYPRE</code> and <code>SuiteSparse</code>.</p> <p>Clone of the default branch</p> <ul> <li>The current installation procedure assumes that the clone of the source files is based on the default branch of each repository.</li> <li>Users are free to consider different branches for their installation.</li> </ul> <p>All sources are collected in a global directory called <code>MFEM4SLOTH</code>. </p> <pre><code>cd $HOME\nmkdir MFEM4SLOTH\ncd MFEM4SLOTH\n</code></pre>"},{"location":"Started/Installation/sources.html#mfem","title":"MFEM","text":"<p>MFEM's source files are obtained by running the following command:</p> <pre><code>git clone https://github.com/mfem/mfem.git\n</code></pre>"},{"location":"Started/Installation/sources.html#hypre","title":"HYPRE","text":"<p>HYPRE's source files are obtained by running the following command:</p> <pre><code>git clone https://github.com/hypre-space/hypre.git\n</code></pre>"},{"location":"Started/Installation/sources.html#metis","title":"METIS","text":"<p>METIS's source files are obtained by running the following commands:</p> <pre><code>git clone https://github.com/mfem/tpls.git\nmv tpls/metis-4.0.3.tar.gz .\ntar -zxvf metis-4.0.3.tar.gz\nrm -fr metis-4.0.3.tar.gz tpls\n</code></pre>"},{"location":"Started/Installation/sources.html#suitesparse","title":"SuiteSparse","text":"<p>SuiteSparse's source files are obtained by running the following command:</p> <pre><code>git clone https://github.com/DrTimothyAldenDavis/SuiteSparse.git\n</code></pre>"},{"location":"Started/Installation/sources.html#building-dependencies","title":"Building dependencies","text":"<p>The second step consists in building <code>METIS</code>, <code>HYPRE</code> and <code>SuiteSparse</code>.</p>"},{"location":"Started/Installation/sources.html#metis_1","title":"METIS","text":"<p>To build <code>METIS</code>, the following command must be run:</p> <pre><code>cd metis-4.0.3\nmake OPTFLAGS=-Wno-error=implicit-function-declaration\ncd ..\nln -s metis-4.0.3 metis-4.0\n</code></pre>"},{"location":"Started/Installation/sources.html#hypre_1","title":"HYPRE","text":"<p>To build <code>HYPRE</code>, the following command must be run:</p> <p><pre><code>cd hypre/src\n./configure --disable-fortran\nmake -j N\ncd ../..\n</code></pre> where <code>N</code> is a user defined number of CPUs.</p>"},{"location":"Started/Installation/sources.html#suitesparse_1","title":"SuiteSparse","text":"<p>To build <code>SuiteSparse</code>, the following commands must be run:</p> <p><pre><code>cd SuiteSparse/\nmake -j N\nmake install DESTDIR=$PWD/INSTALLDIR\nmv INSTALLDIR/usr/local/lib/* lib/\nmv INSTALLDIR/usr/local/include/suitesparse/* include/\nmv INSTALLDIR/usr/local/bin/* bin/\ncd ..\n</code></pre> where <code>N</code> is a user defined number of CPUs.</p> <p>Possible errors</p> <p>Depending the Unix configuration of the user, it is possible to have errors because some dependencies are not found as, for example, <code>MFPR</code>. In that case, these missing dependencies must be installed.  For example, to install <code>MFPR</code> on Ubuntu Jammy, the following command can be run: <pre><code>sudo apt-get install libmpfr-dev\n</code></pre></p>"},{"location":"Started/Installation/sources.html#building-mfem-with-dependencies","title":"Building MFEM with dependencies","text":"<p>Here, we assume that all dependencies are well built according to the previous directives.  At this stage, <code>MFEM</code> can be installed by running the following commands:</p> <pre><code>cd mfem\nmake -j N parallel MFEM_USE_SUITESPARSE=YES --prefix=INSTALLDIR\nmake install\ncd ..\n</code></pre>"},{"location":"Started/Installation/sources.html#sloth-compilation","title":"SLOTH compilation","text":"<p>Once <code>MFEM</code> is installed, priori to compile <code>SLOTH</code>, several environment variables must be defined:</p> <pre><code>    export MFEM_DIR=\"$MFEM4SLOTH/mfem/INSTALLDIR/\"\n    export HYPRE_DIR=\"$MFEM4SLOTH/hypre/src/hypre/\"\n    export METIS_DIR=\"$MFEM4SLOTH/metis-4.0/\"\n    export SuiteSparse_DIR=\"$MFEM4SLOTH/SuiteSparse/\"\n</code></pre> <p>On the use of the  <code>envSloth.sh</code> configuration file</p> <p>These definitions are written into the configuration file <code>envSloth.sh</code> located in the root directory of the <code>SLOTH</code> repository.  The use of this file is recommended to load the <code>MFEM</code> environment before compilling <code>SLOTH</code>.</p> <ul> <li>Load the <code>SLOTH</code> configuration file: <pre><code>source ../envSloth.sh [OPTIONS] --mfem=$MFEM4SLOTH\n</code></pre> where <code>$MFEM4SLOTH</code> is a variable associated with the path towards the <code>MFEM</code> installation (ie <code>$HOME/MFEM4SLOTH</code> in the current description) and [OPTIONS] are: <pre><code>    --release to build SLOTH with Release compiler options \n\n    --optim to build SLOTH with Optim compiler options \n\n    --debug to build SLOTH with Debug compiler options \n\n    --coverage to build SLOTH with Coverage compiler options \n\n    --external to built SLOTH with an external package\n</code></pre></li> </ul> <p>By default, <code>SLOTH</code> is built with release compiler options.</p> <ul> <li>Finally, compile  <pre><code>make -j N \n</code></pre> with N the number of jobs.</li> </ul>"},{"location":"Started/Quality/quality.html","title":"Code quality","text":""},{"location":"Started/Quality/quality.html#static-code-analyis","title":"Static code analyis","text":"<p>CppLint is used to check code quality according to Google's C++ style guide.</p> <p>CppLint is a static code checker that can be easily installed from PyPI:</p> <pre><code>pip install cpplint\n</code></pre> <p>The options considered for static code analysis are:</p> <ul> <li><code>linelength=100</code> to set the maximum allowed line length for your code</li> <li><code>filter=-runtime/references,-build/header_guard,-runtime/string</code></li> </ul> <p>These options are placed in the file CPPLINT.cfg, available in the root of the SLOTH repository.</p> <p>In practice, after loading the SLOTH environement file, using the CMake target  <code>lint</code> enables to run the static code analysis:</p> <pre><code>make lint\n</code></pre>"},{"location":"Started/Quality/quality.html#code-coverage-analysis","title":"Code coverage analysis","text":"<p>Performing code coverage analysis consists of three simple steps:</p> <ul> <li>Compilling SLOTH in coverage mode <pre><code>mkdir build\ncd build\nsource ../envSloth.sh --coverage\nmake -j N\n</code></pre></li> <li>Running the tests (here, for example, all cases stored in the folder <code>tests</code>): <pre><code>ctest -j N\n</code></pre></li> <li>Running the CMake target <code>cc</code> to generate the code coverage analysis within the Coverage folder: <pre><code>make cc\n</code></pre></li> </ul> <p>Code quality control before contributing</p> <p>It is a prerequisite that both static code analysis and code coverage analysis are conducted prior to the incorporation of new functionalities in SLOTH. The results of these two analyses should get better or at least stay the same.</p>"}]}